project_name: "Automatic_Guitar_Transcription"
experiment_name: "FretNet_v1_SynthTab"

data:
  drive_data_path: "/content/drive/MyDrive/Automatic Guitar Transcription/Data Set/SynthTab/npz_files/"
  local_data_path: "/content/local_synthtab_data/"
  path: "/content/drive/MyDrive/Automatic Guitar Transcription/Data Set/SynthTab/npz_files"
  window_size: 200
  batch_size: 30
  validation_split_size: 0.2
  random_state: 42
  num_workers: 4
  
  max_fret: 20 
  include_silence: False

model:
  # src/models/__init__.py içindeki get_model fonksiyonu bu adı kullanacak
  name: "FretNet"
  
  params:
    in_channels: 1
    num_freq: 192 
    num_strings: 6

    rnn_type: "LSTM"            
    rnn_hidden_size: 128      
    rnn_num_layers: 2          
    rnn_bidirectional: True      
    rnn_dropout: 0.25            

loss:
  use_class_weights: True
  class_weights_silence_factor: 0.25
  use_focal: True
  focal_loss_gamma: 2.0

training:
  optimizer: "Adam"
  learning_rate: 0.0005
  epochs: 30
  device: "cuda"
  use_mixed_precision: True

  logging_and_checkpointing:
    use_tensorboard: True
    resume_from_checkpoint: null
    save_epoch_checkpoint_interval: 10

  scheduler:
    name: "StepLR"
    step_size: 500
    gamma: 0.5