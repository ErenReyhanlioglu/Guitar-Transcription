# ------------------ General Project Information ------------------
project_name: "Automatic_Guitar_Transcription"
experiment_name: "TabCNN_GuitarSet_LogisticBank_v1"

# ------------------ Dataset and Feature Definitions ------------------
dataset: "GuitarSet" # "GuitarSet" or "SynthTab"
dataset_configs:
  GuitarSet:
    drive_data_path: "/content/drive/MyDrive/Automatic Guitar Transcription/feature_extraction/segments_500frames_most_active_perfect/"
    local_data_path: "/content/local_guitarset_data/"
  SynthTab:
    drive_data_path: "/content/drive/MyDrive/Automatic Guitar Transcription/feature_extraction/synthtab_all_npz/most_active_frames/"
    local_data_path: "/content/local_synthtab_data/"

feature_definitions:
  cqt: {key: "cqt", in_channels: 1, num_freq: 144}
  hcqt: {key: "hcqt", in_channels: 6, num_freq: 144}
  mel: {key: "mel", in_channels: 1, num_freq: 256}

# ------------------ Data Loading and Processing Parameters ------------------
data:
  active_preparation_mode: "framify" # TabCNN requires 'framify'
  configurations:
    windowing: {window_size: 200}
    framify: {framify_window_size: 9}
  
  active_features: ["hcqt", "mel"]
  batch_size: 4
  num_workers: 2
  validation_split_size: 0.2
  random_state: 42
  hop_length: 512
  sample_rate: 22050

# ------------------ Model Selection and Parameters ------------------
model:
  name: "TabCNN"
  params:
    predict_onsets: false

# ------------------ Instrument Properties (Single Source of Truth) ------------------
instrument:
  tuning: [40, 45, 50, 55, 59, 64]
  min_midi: 40    
  max_midi: 88    
  num_frets: 19 
  num_strings: 6

# ------------------ Loss Function Settings ------------------
loss:
  active_loss: "softmax_groups" # "softmax_groups" or "logistic_bank" 

  use_focal: true                 
  focal_gamma: 2.5                
  use_class_weights: true         
  class_weights_silence_factor: 0.75 

  configurations:
    softmax_groups:
      {}

    logistic_bank:
      lmbda: 1.0          
      focal_alpha: 0.25   

# ------------------ Training Parameters ------------------
training:
  optimizer:
    active_optimizer: "AdamW"
    configurations:
      Adam: {params: {lr: 0.0001}}
      AdamW: {params: {lr: 0.0001, weight_decay: 0.01}}
      
  scheduler:
    active_scheduler: "ReduceLROnPlateau"
    configurations:
      ReduceLROnPlateau: {params: {monitor: "val_tab_f1", mode: "max", factor: 0.2, patience: 5, min_lr: 1.0e-6}}
      StepLR: {params: {step_size: 10, gamma: 0.5}}
      
  epochs: 100
  device: "cuda"
  use_mixed_precision: true
  
  early_stopping:
    enabled: true
    monitor: "val_tab_f1"
    patience: 10
    min_delta: 0.0001
    mode: "max"

# ------------------ Post-Processing Settings ------------------
post_processing:
  min_duration_frames: 0
  prediction_threshold: 0.5
  
# ------------------ Evaluation Metrics Settings ------------------
metrics:
  include_silence: False

# ------------------ Logging and Checkpoint Settings ------------------
logging_and_checkpointing:
  use_tensorboard: True
  resume_from_checkpoint: null
  log_epoch_summary: True
  
  # ------------------------------------------------------------------------------------
  # This section allows for granular control over log verbosity for each part of the project.
  # The hierarchy is: DEBUG > INFO > WARNING > ERROR > CRITICAL.
  # Setting a level to "DEBUG" will show all messages (DEBUG, INFO, WARNING, etc.).
  # Setting it to "INFO" will show INFO, WARNING, ERROR, etc., but hide DEBUG messages.
  # ------------------------------------------------------------------------------------
  log_levels:
    __main__: "INFO"
    src.trainer: "DEBUG"
    src.data_loader: "DEGUB"
    src.utils.losses: "DEBUG"
    src.utils.metrics: "INFO"
    src.utils.agt_tools: "DEBUG"
    src.utils.experiment: "INFO"
    src.utils.analyze_errors: "INFO"
    src.models.tabcnn: "DEBUG"      