# ------------------ General Project Information ------------------
project_name: "Automatic_Guitar_Transcription"
experiment_name: "TabCNN_GuitarSet_LogisticBank_v2"

# ------------------ Dataset and Feature Definitions ------------------
dataset: "GuitarSet" 
dataset_configs:
  GuitarSet:
    drive_data_path: "/content/drive/MyDrive/Automatic Guitar Transcription/feature_extraction/guitarset_all_npz/"
    local_data_path: "/content/local_guitarset_data/"
    feature_to_file_map:
      hcqt: "hcqt.npy"
      mel: "mel.npy"
      power: "power.npy"  

  SynthTab:
    drive_data_path: "/content/drive/MyDrive/Automatic Guitar Transcription/feature_extraction/synthtab_all_npz/most_active_frames/"
    local_data_path: "/content/local_synthtab_data/"
    feature_to_file_map:
      hcqt: "hcqt.npy"
      mel: "melspec.npy"
      power: "power.npy"

feature_definitions:
  cqt: {key: "cqt", in_channels: 1, num_freq: 144}
  hcqt: {key: "hcqt", in_channels: 6, num_freq: 144}
  mel: {key: "mel", in_channels: 1, num_freq: 256}
  power: {key: "power", in_channels: 1, num_freq: 1}

# ------------------ Data Loading and Processing Parameters ------------------
data:
  active_preparation_mode: "framify" 
  configurations:
    windowing: 
      window_size: 200
    framify: 
      framify_chunk_size: 500
      framify_window_size: 9

  augmentation:
    enabled: false  
    time_masking_param: 30 
    freq_masking_param: 24

  active_features: ["hcqt", "mel"]  
  target_keys: ["tablature"] # tablature, onsets, offsets
  batch_size: 4
  num_workers: 2
  random_state: 42
  hop_length: 512
  sample_rate: 22050

# ------------------ Model Selection and Parameters ------------------
model:
  name: "TabCNN"
  params:
    use_projection_layer: true # Activates the projection layers for smart feature fusion.
    projection_output_size: 256 # The common dimension to project HCQT and Mel features into.

# ------------------ Instrument Properties (Single Source of Truth) ------------------
instrument:
  tuning: [40, 45, 50, 55, 59, 64]
  min_midi: 40  
  max_midi: 88  
  num_frets: 19
  num_strings: 6

# ------------------ Loss Function Settings ------------------
loss:
  active_loss: "softmax_groups" # "softmax_groups" or "logistic_bank"

  configurations:
    softmax_groups:
      type: "CustomSoftmaxTablatureLoss" # "CrossEntropyLoss" or "CustomSoftmaxTablatureLoss"
      custom_softmax_penalties: # bunlara std değerleri eklenecek base değerler arasında eğitim boyunca bu aralıkta dinamik bir şekilde belirlenecek losslar
        miss: 1.0
        false_alarm: 1.0
        substitution: 1.0
      use_focal: false
      focal_params:
        gamma: 2.0
      use_class_weights: true
      class_weights_params:
        silence_factor: 0.6

    logistic_bank:
      type: "CustomLogisticTablatureLoss" # "BCEWithLogitsLoss" or "CustomLogisticTablatureLoss"
      lmbda: 0.01
      use_focal: true
      focal_params:
        gamma: 2.5
        alpha: 0.75  

  auxiliary_loss:
    enabled: True
    type: "BCEWithLogitsLoss"
    weight: 0.4    

  onset_loss:
    enabled: false
    type: "BCEWithLogitsLoss"
    weight: 0.4 

  offset_loss:
    enabled: false
    type: "BCEWithLogitsLoss"
    weight: 0.4 

# ------------------ Training Parameters ------------------
training:
  optimizer:
    active_optimizer: "AdamW" 
    configurations:
      Adam: 
        differential_lr: true
        params:
          backbone_lr: 0.0001 
          head_lr: 0.0005 
          weight_decay: 0.0
      AdamW:
        differential_lr: true
        params:
          backbone_lr: 0.0005 
          head_lr: 0.0005 
          weight_decay: 0.01
      
  scheduler:
    active_scheduler: "ReduceLROnPlateau" # "ReduceLROnPlateau", "StepLR", or "none"
    configurations:
      ReduceLROnPlateau: {params: {monitor: "val_tab_f1_macro", mode: "max", factor: 0.2, patience: 5, min_lr: 1.0e-6}}
      StepLR: {params: {step_size: 10, gamma: 0.5}}
      
  epochs: 150
  device: "cuda"
  use_mixed_precision: true
  
  early_stopping:
    enabled: true
    monitor: "val_tab_f1_macro"
    patience: 10
    min_delta: 0.0001
    mode: "max"

# ------------------ Post-Processing Settings ------------------
post_processing:
  min_duration_frames: 0 # Short note filter (0 = disabled)
  prediction_threshold: 0.3 # Probability threshold  
  
# ------------------ Evaluation Metrics Settings ------------------
metrics:
  include_silence: True # Include/exclude silence class in metrics

# ------------------ Logging and Checkpoint Settings ------------------
logging_and_checkpointing:
  use_tensorboard: True
  resume_from_checkpoint: null
  log_epoch_summary: True

  # ------------------------------------------------------------------------------------
  # This section allows for granular control over log verbosity for each part of the project.
  # The hierarchy is: DEBUG > INFO > WARNING > ERROR > CRITICAL.
  # Setting a level to "DEBUG" will show all messages (DEBUG, INFO, WARNING, etc.).
  # Setting it to "INFO" will show INFO, WARNING, ERROR, etc., but hide DEBUG messages.
  # ------------------------------------------------------------------------------------
  log_levels:
    __main__: "INFO"
    src.trainer: "DEBUG"  
    src.data_loader: "INFO"  
    src.models.tabcnn: "DEBUG"
    src.utils.losses: "INFO"  
    src.utils.metrics: "INFO"
    src.utils.agt_tools: "INFO"
    src.utils.experiment: "INFO"
    src.utils.analyze_errors: "INFO"